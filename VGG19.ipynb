{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuRPu+09CtW6wbsWJb3Tpb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/deep_learning_illustrated/blob/CNN/VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# Load dependencies:\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential # Changed 'sequential' to 'Sequential'\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import image_dataset_from_directory # Changed import to reflect updated location of ImageDataGenerator"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pUjmdkwEXDmX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranfer Learning -using VGG19 as the convolutional base of VGG19\n",
        "This code snippet demonstrates the use of the VGG19 model, a well-known deep convolutional neural network (CNN) architecture, pre-trained on the ImageNet dataset. Here's a step-by-step explanation of what each part does:\n",
        "\n",
        "-------------\n",
        "## Loading the VGG19 model:\n",
        "\n",
        "    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(224,224, 3), pooling=None)\n",
        "\n",
        "## VGG19():\n",
        "Loads the VGG19 model.\n",
        "\n",
        "---------\n",
        "## Include_top=False:\n",
        "This means that the model is loaded without the fully connected (classification) layers at the top, leaving only the convolutional base of the network.\n",
        "\n",
        "This is common in transfer learning when you want to use the model for a new task but only retain its feature extraction layers.\n",
        "\n",
        "--------------\n",
        "##weights='imagenet':\n",
        "Specifies that the model should use pre-trained weights that were learned on the ImageNet dataset, a large dataset with millions of labeled images.\n",
        "\n",
        "-----------------\n",
        "##input_shape=(224,224,3): Defines the input shape for the model.\n",
        "\n",
        "In this case, it's an image with dimensions of 224x224 pixels and 3 channels (for RGB color images).\n",
        "\n",
        "--------------\n",
        "##pooling=None:\n",
        "\n",
        "No pooling is applied in this case.\n",
        "\n",
        "If you wanted global pooling, you could set this to 'avg' for global average pooling or 'max' for global max pooling.\n",
        "\n",
        "\n",
        "----------------------\n",
        "##Freezing the layers of VGG19:\n",
        "\n",
        "    for layer in vgg19.layers:\n",
        "       layer.trainable = False\n",
        "\n",
        "-------------\n",
        "##Freezing layers:\n",
        "\n",
        "This ensures that all the layers in the VGG19 model are not trainable.\n",
        "\n",
        "When a layer is set to trainable = False, the weights of that layer will remain unchanged during training.\n",
        "\n",
        "This is a common step in transfer learning, where the idea is to use the pre-trained weights for feature extraction and prevent the model from updating those weights during training.\n",
        "\n",
        "You typically add new layers on top of the frozen base model, and only train those new layers while using the frozen layers for feature extraction.\n",
        "\n",
        "-------------------\n",
        "In summary, this snippet loads the VGG19 convolutional base with pre-trained ImageNet weights, and then freezes the layers to ensure they are not updated during training.\n",
        "\n",
        "This setup is used for transfer learning tasks, where the base model serves as a feature extractor."
      ],
      "metadata": {
        "id": "Q67zRTPoYQQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG19 model:\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet',\n",
        "input_shape=(224,224, 3), pooling=None)\n",
        "# Freeze all the layers in the base VGGNet19 model:\n",
        "for layer in vgg19.layers: layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu-YJS26Wok4",
        "outputId": "9d5ff70c-7a9c-413d-d079-039011d3b504"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the VGG19 model from the ImageNet\n",
        "This code loads the VGG19 model with pre-trained weights from ImageNet for transfer learning.\n",
        "\n",
        "The first line loads the VGG19 model without the top classification layers\n",
        "\n",
        "    (include_top=False), using pre-trained weights from ImageNet (weights='imagenet')\n",
        "\n",
        "The input shape is set to 224x224 pixels with 3 color channels\n",
        "\n",
        "    (input_shape=(224,224,3)),\n",
        "\n",
        "and no pooling is applied\n",
        "\n",
        "    (pooling=None)\n",
        "\n",
        "------------------\n",
        "The second line iterates through each layer in the model and sets its trainable attribute to False.\n",
        "\n",
        "This freezes the layers, preventing their weights from being updated during training.\n",
        "\n",
        "This is commonly done in transfer learning to leverage the pre-trained features for a new task."
      ],
      "metadata": {
        "id": "W_dO_VutbK3v"
      }
    }
  ]
}